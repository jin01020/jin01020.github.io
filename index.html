<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Jinyoung Choi </title> <meta name="author" content="Jinyoung Choi"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%98%BA&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jin0.1020.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <div id="particles-js"></div> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Jinyoung</span> Choi </h1> <p class="desc"><a href="http://ee.snu.ac.kr/en" rel="external nofollow noopener" target="_blank">ECE, SNU, Seoul, Republic of Korea</a>. jin0.choi at snu.ac.kr</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/my_photo.jpg" sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/my_photo.jpg?d1eefaaed79e61f7e9c6b7f48d7dbba5" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="my_photo.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hi, I’m a PhD candidate at <a href="https://en.snu.ac.kr/index.html" rel="external nofollow noopener" target="_blank">Seoul National University</a> in <a href="http://ee.snu.ac.kr/en" rel="external nofollow noopener" target="_blank">Electrical &amp; Computer Engineering</a>, wrapping up my doctoral journey in <a href="http://cv.snu.ac.kr" rel="external nofollow noopener" target="_blank">Computer Vision Lab</a> under <a href="https://cv.snu.ac.kr/index.php/~bhhan/" rel="external nofollow noopener" target="_blank">Prof. Bohyung Han</a>. Prior to this, I studied Industrial Management Engineering and Mathematics at <a href="https://www.postech.ac.kr/eng/index.do" rel="external nofollow noopener" target="_blank">POSTECH</a>.</p> <p>My current passion lies in generative models, particularly research that bridges mathematical theory and practical applications, essentially translating mathematical insights into solutions that matter. I’m excited to contribute to the growing world of generative AI.</p> <p>Feel free to reach out at <a href="mailto:jin0.choi@snu.ac.kr">jin0.choi at snu.ac.kr</a> for any inquiries or to chat about research!</p> <div class="navbar-brand social"> <a href="mailto:%6A%69%6E%30.%63%68%6F%69@%73%6E%75.%61%63.%6B%72" title="email"><i class="fa-solid fa-envelope" style="font-size: 40px;"></i></a> <a href="https://scholar.google.com/citations?user=oTv2BygAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar" style="font-size: 40px;"></i></a> <a href="https://github.com/jin01020" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github" style="font-size: 40px;"></i></a> </div> </div> <br> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jul 2025</th> <td> I succesfully defended my PhD dissertation! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <h7> <a>*denotes equal contribution</a> </h7> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/rx-dpm.jpg" sizes="200px"> <img src="/assets/img/publication_preview/rx-dpm.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rx-dpm.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="enhanced2024choi" class="col-sm-8"> <div class="title">Enhanced Diffusion Sampling via Extrapolation with Multiple ODE Solutions</div> <div class="author"> <em>Jinyoung Choi</em>, <a href="https://junoh-kang.github.io/" rel="external nofollow noopener" target="_blank">Junoh Kang</a>, and <a href="https://cv.snu.ac.kr/index.php/~bhhan/" rel="external nofollow noopener" target="_blank">Bohyung Han</a> </div> <div class="periodical"> <em>In ICLR</em>, 2025 </div> <div class="periodical"> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2504.01855" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/jin01020/rx-dpm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Diffusion probabilistic models (DPMs), while effective in generating high-quality samples, often suffer from high computational costs due to their iterative sampling process. To address this, we propose an enhanced ODE-based sampling method for DPMs inspired by Richardson extrapolation, which reduces numerical error and improves convergence rates. Our method, RX-DPM, leverages multiple ODE solutions at intermediate time steps to extrapolate the denoised prediction in DPMs. This significantly enhances the accuracy of estimations for the final sample while maintaining the number of function evaluations (NFEs). Unlike standard Richardson extrapolation, which assumes uniform discretization of the time grid, we develop a more general formulation tailored to arbitrary time step scheduling, guided by local truncation error derived from a baseline sampling method. The simplicity of our approach facilitates accurate estimation of numerical solutions without significant computational overhead, and allows for seamless and convenient integration into various DPMs and solvers. Additionally, RX-DPM provides explicit error estimates, effectively demonstrating the faster convergence as the leading error term’s order increases. Through a series of experiments, we show that the proposed method improves the quality of generated samples without requiring additional sampling iterations.</p> </div> <div class="tldr"></div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fifo.png" sizes="200px"> <img src="/assets/img/publication_preview/fifo.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fifo.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="kim2024fifo" class="col-sm-8"> <div class="title">FIFO-Diffusion: Generating Infinite Videos from Text without Training</div> <div class="author"> Jihwan Kim<sup>*</sup>, <a href="https://junoh-kang.github.io/" rel="external nofollow noopener" target="_blank">Junoh Kang<sup>*</sup></a>, <em>Jinyoung Choi</em>, and <a href="https://cv.snu.ac.kr/index.php/~bhhan/" rel="external nofollow noopener" target="_blank">Bohyung Han</a> </div> <div class="periodical"> <em>In NeurIPS</em>, 2024 </div> <div class="periodical"> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://jjihwan.github.io/projects/FIFO-Diffusion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">project page</a> <a href="http://arxiv.org/abs/2405.11473" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/jjihwan/FIFO-Diffusion_public" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We propose a novel inference technique based on a pretrained diffusion model for text-conditional video generation. Our approach, called FIFO-Diffusion, is conceptually capable of generating infinitely long videos without training. This is achieved by iteratively performing diagonal denoising, which concurrently processes a series of consecutive frames with increasing noise levels in a queue; our method dequeues a fully denoised frame at the head while enqueuing a new random noise frame at the tail. However, diagonal denoising is a double-edged sword as the frames near the tail can take advantage of cleaner ones by forward reference but such a strategy induces the discrepancy between training and inference. Hence, we introduce latent partitioning to reduce the training-inference gap and lookahead denoising to leverage the benefit of forward referencing. We have demonstrated the promising results and effectiveness of the proposed methods on existing textto-video generation baselines. Generated video samples and source codes are available at our project page.</p> </div> <div class="tldr"></div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ogdm.jpg" sizes="200px"> <img src="/assets/img/publication_preview/ogdm.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ogdm.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="kang2024observation" class="col-sm-8"> <div class="title">Observation-Guided Diffusion Probabilistic Models</div> <div class="author"> <a href="https://junoh-kang.github.io/" rel="external nofollow noopener" target="_blank">Junoh Kang<sup>*</sup></a>, <em>Jinyoung Choi<sup>*</sup></em>, Sungik Choi, and <a href="https://cv.snu.ac.kr/index.php/~bhhan/" rel="external nofollow noopener" target="_blank">Bohyung Han</a> </div> <div class="periodical"> <em>In CVPR</em>, 2024 </div> <div class="periodical"> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2310.04041" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/Junoh-Kang/OGDM_edm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We propose a novel diffusion-based image generation method called the observation-guided diffusion probabilistic model (OGDM), which effectively addresses the tradeoff between quality control and fast sampling. Our approach reestablishes the training objective by integrating the guidance of the observation process with the Markov chain in a principled way. This is achieved by introducing an additional loss term derived from the observation based on a conditional discriminator on noise level, which employs a Bernoulli distribution indicating whether its input lies on the (noisy) real manifold or not. This strategy allows us to optimize the more accurate negative log-likelihood induced in the inference stage especially when the number of function evaluations is limited. The proposed training scheme is also advantageous even when incorporated only into the fine-tuning process, and it is compatible with various fast inference strategies since our method yields better denoising networks using the exactly the same inference procedure without incurring extra computational cost. We demonstrate the effectiveness of our training algorithm using diverse inference techniques on strong diffusion model baselines. Our implementation is available at https://github.com/Junoh-Kang/OGDM_edm.</p> </div> <div class="tldr"></div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mcl-gan.jpg" sizes="200px"> <img src="/assets/img/publication_preview/mcl-gan.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mcl-gan.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="choi2022mcl" class="col-sm-8"> <div class="title">MCL-GAN: Generative Adversarial Networks with Multiple Specialized Discriminators</div> <div class="author"> <em>Jinyoung Choi</em>, and <a href="https://cv.snu.ac.kr/index.php/~bhhan/" rel="external nofollow noopener" target="_blank">Bohyung Han</a> </div> <div class="periodical"> <em>In NeurIPS</em>, 2022 </div> <div class="periodical"> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2107.07260" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="abstract hidden"> <p>We propose a framework of generative adversarial networks with multiple discriminators, which collaborate to represent a real dataset more effectively. Our approach facilitates learning a generator consistent with the underlying data distribution based on real images and thus mitigates the chronic mode collapse problem. From the inspiration of multiple choice learning, we guide each discriminator to have expertise in a subset of the entire data and allow the generator to find reasonable correspondences between the latent and real data spaces automatically without extra supervision for training examples. Despite the use of multiple discriminators, the backbone networks are shared across the discriminators and the increase in training cost is marginal. We demonstrate the effectiveness of our algorithm using multiple evaluation metrics in the standard datasets for diverse tasks.</p> </div> <div class="tldr"></div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge rounded w-100">ICCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/qmap.png" sizes="200px"> <img src="/assets/img/publication_preview/qmap.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="qmap.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="song2021variable" class="col-sm-8"> <div class="title">Variable-Rate Deep Image Compression through Spatially-Adaptive Feature Transform</div> <div class="author"> Myungseo Song, <em>Jinyoung Choi</em>, and <a href="https://cv.snu.ac.kr/index.php/~bhhan/" rel="external nofollow noopener" target="_blank">Bohyung Han</a> </div> <div class="periodical"> <em>In ICCV</em>, 2021 </div> <div class="periodical"> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2108.09551" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://github.com/micmic123/QmapCompression" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We propose a versatile deep image compression network based on Spatial Feature Transform (SFT), which takes a source image and a corresponding quality map as inputs and produce a compressed image with variable rates. Our model covers a wide range of compression rates using a single model, which is controlled by arbitrary pixel-wise quality maps. In addition, the proposed framework allows us to perform task-aware image compressions for various tasks, e.g., classification, by efficiently estimating optimized quality maps specific to target tasks for our encoding network. This is even possible with a pretrained network without learning separate models for individual tasks. Our algorithm achieves outstanding rate-distortion trade-off compared to the approaches based on multiple models that are optimized separately for several different target rates. At the same level of compression, the proposed approach successfully improves performance on image classification and text region quality preservation via task-aware quality map estimation without additional model training. The code is available at the project website: https://github.com/micmic123/QmapCompression.</p> </div> <div class="tldr"></div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-3 abbr"> <abbr class="badge rounded w-100">ECCV</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/jpeg_quant.png" sizes="200px"> <img src="/assets/img/publication_preview/jpeg_quant.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="jpeg_quant.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="choi2020task" class="col-sm-8"> <div class="title">Task-Aware Quantization Network for JPEG Image Compression</div> <div class="author"> <em>Jinyoung Choi</em>, and <a href="https://cv.snu.ac.kr/index.php/~bhhan/" rel="external nofollow noopener" target="_blank">Bohyung Han</a> </div> <div class="periodical"> <em>In ECCV</em>, 2020 </div> <div class="periodical"> </div> <div> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650307.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">paper</a> </div> <div class="abstract hidden"> <p>We propose to learn a deep neural network for JPEG image compression, which predicts image-specific optimized quantization tables fully compatible with the standard JPEG encoder and decoder. Moreover, our approach provides the capability to learn task-specific quantization tables in a principled way by adjusting the objective function of the network. The main challenge to realize this idea is that there exist non-differentiable components in the encoder such as run-length encoding and Huffman coding and it is not straightforward to predict the probability distribution of the quantized image representations. We address these issues by learning a differentiable loss function that approximates bitrates using simple network blocks—two MLPs and an LSTM. We evaluate the proposed algorithm using multiple task-specific losses—two for semantic image understanding and another two for conventional image compression—and demonstrate the effectiveness of our approach to the individual tasks.</p> </div> <div class="tldr"></div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jinyoung Choi. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?ca282e7930508760acb5a112948f55e9"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>